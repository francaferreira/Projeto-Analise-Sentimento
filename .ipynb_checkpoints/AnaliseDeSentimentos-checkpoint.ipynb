{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f12a0f-70e2-4605-8b4f-4b23b5b387c3",
   "metadata": {},
   "source": [
    "# ============================\n",
    "\n",
    "# An√°lise de sentimentos\n",
    "Hoje, as empresas buscam compreender os pontos fracos de seus lan√ßamentos e a percep√ß√£o do p√∫blico sobre seus servi√ßos, produtos e marca. Para isso, podem contar com a an√°lise de sentimento, uma t√©cnica que mede com precis√£o as opini√µes expressas em textos, como coment√°rios e avalia√ß√µes.\n",
    "\n",
    "Essa an√°lise pode ser feita com o aux√≠lio de ferramentas prontas (como RandomForestClassifie ,TfidfVectorizer e NLTK) ou com modelos treinados para um setor espec√≠fico. Al√©m disso, atualmente √© poss√≠vel ir al√©m: √© vi√°vel organizar automaticamente os coment√°rios por temas ‚Äî identificando, por exemplo, men√ß√µes a \"atendimento\", \"pre√ßo\" ou \"qualidade\" ‚Äî mesmo sem ter classifica√ß√µes pr√©vias, utilizando m√©todos de aprendizado n√£o supervisionado.\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497269dd-8602-44b0-b442-1d81c7abb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. IMPORTANDO BIBLIOTECAS\n",
    "# ============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d5da3f-1e23-4607-ae90-8a898ccb8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ferramentas espec√≠ficas do NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Ferramentas do Scikit-learn para machine learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33251a44-93a3-44f9-89c7-5530a36d66db",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 2. BAIXAR RECURSOS DO NLTK\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b74135-47dd-4fa3-b5cc-4ba7c7c517a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando recursos do NLTK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baixando recursos do NLTK...\")\n",
    "nltk.download('punkt_tab')  # Adicionado: necess√°rio para tokeniza√ß√£o em portugu√™s\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64eeb67-15cb-4d9c-9cc0-194dd59372fe",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 3. CARREGAR OS DADOS\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6ffa60-34f2-4998-b7c2-f3d28d91dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "Total de cr√≠ticas: 49459\n",
      "Colunas dispon√≠veis: ['id', 'text_en', 'text_pt', 'sentiment']\n",
      "\n",
      "Distribui√ß√£o dos sentimentos:\n",
      "sentiment\n",
      "neg    24765\n",
      "pos    24694\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Carregando dados...\")\n",
    "data = pd.read_csv('imdb-reviews-pt-br.csv')\n",
    "\n",
    "print(f\"Total de cr√≠ticas: {len(data)}\")\n",
    "print(f\"Colunas dispon√≠veis: {list(data.columns)}\")\n",
    "print(f\"\\nDistribui√ß√£o dos sentimentos:\")\n",
    "print(data['sentiment'].value_counts())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44b898-4d40-439d-a17d-3661dcfe81e4",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 4. PR√â-PROCESSAMENTO MELHORADO\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3591745a-6caf-46b4-a3e6-40a7c104ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando textos...\n",
      "\n",
      "Exemplo de pr√©-processamento:\n",
      "Original (primeiras 200 caracteres):\n",
      "Mais uma vez, o Sr. Costner arrumou um filme por muito mais tempo do que o necess√°rio. Al√©m das terr√≠veis seq√º√™ncias de resgate no mar, das quais h√° muito poucas, eu simplesmente n√£o me importei com n\n",
      "\n",
      "Limpo:\n",
      "vez costn arrum film temp necess√°ri al√©m terr√≠v seq √™nci resgat mar qua pouc simples import nenhum personagens maior fantasm arm√°ri personag costers realiz log in√≠ci esquec tard import personag dev im\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def preprocessamento_avancado(texto):\n",
    "    \"\"\"\n",
    "    Limpa e prepara o texto para an√°lise.\n",
    "    Vers√£o corrigida: mant√©m palavras inteiras, n√£o letras soltas.\n",
    "    \"\"\"\n",
    "    # Verifica se √© texto v√°lido\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Converter para min√∫sculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # 2. Remover tags HTML (se houver)\n",
    "    texto = re.sub(r'<.*?>', ' ', texto)\n",
    "    \n",
    "    # 3. Manter apenas letras (com acentos) e espa√ßos\n",
    "    texto = re.sub(r'[^a-z√°√©√≠√≥√∫√¢√™√Æ√¥√ª√£√µ√ß√†√®√¨√≤√π\\\\s]', ' ', texto)\n",
    "    \n",
    "    # 4. Remover espa√ßos m√∫ltiplos\n",
    "    texto = re.sub(r'\\\\s+', ' ', texto)\n",
    "    \n",
    "    # 5. Tokeniza√ß√£o: dividir em palavras individuais\n",
    "    palavras = word_tokenize(texto, language='portuguese')\n",
    "    \n",
    "    # 6. Remover stopwords (palavras irrelevantes)\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    palavras_filtradas = [p for p in palavras if p not in stop_words and len(p) > 2]\n",
    "    \n",
    "    # 7. Stemming: reduzir palavras √† raiz\n",
    "    stemmer = SnowballStemmer('portuguese')\n",
    "    palavras_stem = [stemmer.stem(p) for p in palavras_filtradas]\n",
    "    \n",
    "    # 8. Juntar palavras novamente em um texto\n",
    "    return ' '.join(palavras_stem)\n",
    "\n",
    "print(\"Processando textos...\")\n",
    "# Aplicar a fun√ß√£o de pr√©-processamento a cada cr√≠tica\n",
    "data['texto_limpo'] = data['text_pt'].apply(preprocessamento_avancado)\n",
    "\n",
    "# Mostrar exemplo do pr√©-processamento\n",
    "print(\"\\nExemplo de pr√©-processamento:\")\n",
    "print(\"Original (primeiras 200 caracteres):\")\n",
    "print(data['text_pt'].iloc[0][:200])\n",
    "print(\"\\nLimpo:\")\n",
    "print(data['texto_limpo'].iloc[0][:200])\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052693b-270e-45e1-8fe3-d71e9df4ce45",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 5. PREPARAR DADOS PARA MODELO\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7cd69a-ea3f-4549-9273-1cd865fa57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (49459,)\n",
      "Shape de y: (49459,)\n"
     ]
    }
   ],
   "source": [
    "# Converter sentimentos para n√∫meros: 0 = negativo, 1 = positivo\n",
    "y = data['sentiment'].map({'neg': 0, 'pos': 1}).values\n",
    "\n",
    "# Usar textos limpos como entrada\n",
    "X = data['texto_limpo'].values\n",
    "\n",
    "print(f\"Shape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea9918-61a6-4ec1-8cca-afc3ccb86cc1",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 6. DIVIDIR DADOS EM TREINO E TESTE\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5648df49-8c97-46e8-aa5a-87afd0faeb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Divis√£o dos dados:\n",
      "Treino: 39567 amostras\n",
      "Teste: 9892 amostras\n",
      "Propor√ß√£o positiva no treino: 49.93%\n",
      "Propor√ß√£o positiva no teste: 49.93%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nDivis√£o dos dados:\")\n",
    "print(f\"Treino: {len(X_train)} amostras\")\n",
    "print(f\"Teste: {len(X_test)} amostras\")\n",
    "print(f\"Propor√ß√£o positiva no treino: {y_train.mean():.2%}\")\n",
    "print(f\"Propor√ß√£o positiva no teste: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2491cc8f-2c68-467e-94db-de1838bee5a4",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 7. CRIAR E OTIMIZAR O PIPELINE\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47d5e3c-9fcb-482f-afa3-5d6e78b64c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CRIANDO E OTIMIZANDO O MODELO\n",
      "============================================================\n",
      "\n",
      "Iniciando otimiza√ß√£o com GridSearchCV...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Otimiza√ß√£o conclu√≠da!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CRIANDO E OTIMIZANDO O MODELO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pipeline: sequ√™ncia de etapas que ser√£o executadas em ordem\n",
    "pipeline = Pipeline([\n",
    "    # Etapa 1: Transformar texto em n√∫meros\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=5,\n",
    "        max_df=0.7,\n",
    "        stop_words=stopwords.words('portuguese')\n",
    "    )),\n",
    "    \n",
    "    # Etapa 2: Classificador\n",
    "    ('clf', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Par√¢metros para otimiza√ß√£o (vers√£o simplificada para execu√ß√£o mais r√°pida)\n",
    "parametros = {\n",
    "    'tfidf__max_features': [3000, 5000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__n_estimators': [100, 150],\n",
    "    'clf__max_depth': [None, 20]\n",
    "}\n",
    "\n",
    "print(\"\\nIniciando otimiza√ß√£o com GridSearchCV...\")\n",
    "\n",
    "# GridSearchCV com menos folds para execu√ß√£o mais r√°pida\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parametros,\n",
    "    cv=3,  # Reduzido de 5 para 3 para execu√ß√£o mais r√°pida\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Treinar o modelo com otimiza√ß√£o\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nOtimiza√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3fa7b-b3cd-4379-a4d1-f929c83c1329",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 8. AVALIAR RESULTADOS\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72be8c9-4837-4cf7-be5c-e6cac1bbe2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTADOS DA OTIMIZA√á√ÉO\n",
      "============================================================\n",
      "\n",
      "Melhor acur√°cia na valida√ß√£o: 0.8461\n",
      "Melhores par√¢metros encontrados:\n",
      "  clf__max_depth: None\n",
      "  clf__n_estimators: 150\n",
      "  tfidf__max_features: 5000\n",
      "  tfidf__ngram_range: (1, 2)\n",
      "\n",
      "Avaliando no conjunto de teste...\n",
      "\n",
      "üéØ ACUR√ÅCIA FINAL NO TESTE: 0.8469\n",
      "   (84.7% de acerto)\n",
      "\n",
      "üìä RELAT√ìRIO DETALHADO:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.84      0.85      0.85      4953\n",
      "    positivo       0.85      0.84      0.85      4939\n",
      "\n",
      "    accuracy                           0.85      9892\n",
      "   macro avg       0.85      0.85      0.85      9892\n",
      "weighted avg       0.85      0.85      0.85      9892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS DA OTIMIZA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Melhores resultados encontrados\n",
    "print(f\"\\nMelhor acur√°cia na valida√ß√£o: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Melhores par√¢metros encontrados:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Testar no conjunto de teste\n",
    "print(\"\\nAvaliando no conjunto de teste...\")\n",
    "y_pred = grid_search.predict(X_test)\n",
    "acuracia_teste = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüéØ ACUR√ÅCIA FINAL NO TESTE: {acuracia_teste:.4f}\")\n",
    "print(f\"   ({acuracia_teste*100:.1f}% de acerto)\")\n",
    "\n",
    "# Relat√≥rio detalhado\n",
    "print(\"\\nüìä RELAT√ìRIO DETALHADO:\")\n",
    "print(classification_report(y_test, y_pred, \n",
    "                           target_names=['negativo', 'positivo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895e332-2510-4645-a822-e356f83534c2",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 9. EXEMPLO DE USO DO MODELO\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2a2a00-d72a-49b9-8155-77b1ef654371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMO USAR O MODELO PARA NOVAS CR√çTICAS\n",
      "============================================================\n",
      "\n",
      "Testando o modelo com exemplos novos:\n",
      "\n",
      "Exemplo 1:\n",
      "Texto: Este filme √© incr√≠vel! A atua√ß√£o foi perfeita e a hist√≥ria emocionante.\n",
      "Sentimento previsto: POSITIVO\n",
      "\n",
      "Exemplo 2:\n",
      "Texto: Que decep√ß√£o! Perdi duas horas da minha vida com este filme ruim.\n",
      "Sentimento previsto: NEGATIVO\n",
      "\n",
      "Exemplo 3:\n",
      "Texto: N√£o gostei muito, mas tem alguns momentos bons.\n",
      "Sentimento previsto: POSITIVO\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMO USAR O MODELO PARA NOVAS CR√çTICAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Exemplo de predi√ß√£o\n",
    "exemplos = [\n",
    "    \"Este filme √© incr√≠vel! A atua√ß√£o foi perfeita e a hist√≥ria emocionante.\",\n",
    "    \"Que decep√ß√£o! Perdi duas horas da minha vida com este filme ruim.\",\n",
    "    \"N√£o gostei muito, mas tem alguns momentos bons.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTestando o modelo com exemplos novos:\")\n",
    "for i, texto in enumerate(exemplos):\n",
    "    texto_limpo = preprocessamento_avancado(texto)\n",
    "    predicao = grid_search.predict([texto_limpo])[0]\n",
    "    sentimento = \"POSITIVO\" if predicao == 1 else \"NEGATIVO\"\n",
    "    print(f\"\\nExemplo {i+1}:\")\n",
    "    print(f\"Texto: {texto}\")\n",
    "    print(f\"Sentimento previsto: {sentimento}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87433e8-22a4-46c6-9820-c249cbe8c9f3",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 10. CONCLUS√ÉO\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbbbf5af-c774-47a4-b95b-2f1a9cb8d093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMO DO PROJETO\n",
      "============================================================\n",
      "\n",
      "‚úÖ O QUE FOI FEITO:\n",
      "   1. Corrigido pr√©-processamento (palavras inteiras)\n",
      "   2. Implementado TF-IDF (melhor que CountVectorizer)\n",
      "   3. Usado Random Forest (mais robusto que Naive Bayes)\n",
      "   4. Otimizado hiperpar√¢metros com GridSearchCV\n",
      "   5. Avalia√ß√£o rigorosa com valida√ß√£o cruzada\n",
      "\n",
      "üìä RESULTADO: 84.7% de acur√°cia\n",
      "\n",
      "üéâ PARAB√âNS! Meta de 80% atingida!\n",
      "   Para 90%, considere as sugest√µes de melhoria.\n",
      "\n",
      "============================================================\n",
      "FIM DA AN√ÅLISE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO DO PROJETO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ O QUE FOI FEITO:\")\n",
    "print(\"   1. Corrigido pr√©-processamento (palavras inteiras)\")\n",
    "print(\"   2. Implementado TF-IDF (melhor que CountVectorizer)\")\n",
    "print(\"   3. Usado Random Forest (mais robusto que Naive Bayes)\")\n",
    "print(\"   4. Otimizado hiperpar√¢metros com GridSearchCV\")\n",
    "print(\"   5. Avalia√ß√£o rigorosa com valida√ß√£o cruzada\")\n",
    "\n",
    "print(f\"\\nüìä RESULTADO: {acuracia_teste*100:.1f}% de acur√°cia\")\n",
    "\n",
    "if acuracia_teste > 0.8:\n",
    "    print(\"\\nüéâ PARAB√âNS! Meta de 80% atingida!\")\n",
    "    print(\"   Para 90%, considere as sugest√µes de melhoria.\")\n",
    "else:\n",
    "    print(f\"\\nüìà PARA MELHORAR: {acuracia_teste*100:.1f}%\")\n",
    "    print(\"   Implemente as sugest√µes da se√ß√£o 'Pr√≥ximos Passos'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIM DA AN√ÅLISE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c18fd-0448-4f13-a784-5e72c8f9999b",
   "metadata": {},
   "source": [
    "README.md - AN√ÅLISE DE SENTIMENTOS EM CR√çTICAS DE FILMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426ec7c-80f9-40c0-983d-104d25f37510",
   "metadata": {},
   "source": [
    "# üé¨ An√°lise de Sentimentos em Cr√≠ticas de Filmes\n",
    "\n",
    "![Python](https://img.shields.io/badge/Python-3.8%2B-blue)\n",
    "![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3%2B-orange)\n",
    "![NLTK](https://img.shields.io/badge/NLTK-3.8%2B-green)\n",
    "![Status](https://img.shields.io/badge/Status-Conclu√≠do-success)\n",
    "\n",
    "## üìã Sobre o Projeto\n",
    "\n",
    "Este projeto implementa um sistema de classifica√ß√£o de sentimentos que analisa cr√≠ticas de filmes em portugu√™s e classifica-as como **positivas** ou **negativas**. O objetivo √© atingir uma acur√°cia de **80-90%** utilizando t√©cnicas modernas de Processamento de Linguagem Natural (PLN) e Machine Learning.\n",
    "\n",
    "## üéØ Objetivos\n",
    "\n",
    "- [x] Implementar pipeline completo de pr√©-processamento de texto\n",
    "- [x] Utilizar TF-IDF para vetoriza√ß√£o de features\n",
    "- [x] Treinar modelo Random Forest com otimiza√ß√£o autom√°tica\n",
    "- [x] Avaliar performance com valida√ß√£o cruzada\n",
    "- [x] Criar sistema preditivo para novas cr√≠ticas\n",
    "\n",
    "## üìä Dataset\n",
    "\n",
    "- **Fonte**: Dataset IMDB Reviews em Portugu√™s\n",
    "- **Total de cr√≠ticas**: 49,459\n",
    "- **Distribui√ß√£o balanceada**:\n",
    "  - Negativas (neg): 24,765\n",
    "  - Positivas (pos): 24,694\n",
    "- **Colunas dispon√≠veis**: `id`, `text_en`, `text_pt`, `sentiment`\n",
    "\n",
    "## üèóÔ∏è Arquitetura do Sistema\n",
    "\n",
    "### 1. **Pr√©-processamento de Texto**\n",
    "```python\n",
    "Etapas do pr√©-processamento:\n",
    "1. Convers√£o para min√∫sculas\n",
    "2. Remo√ß√£o de tags HTML\n",
    "3. Filtro de caracteres especiais\n",
    "4. Tokeniza√ß√£o em portugu√™s\n",
    "5. Remo√ß√£o de stopwords\n",
    "6. Stemming (redu√ß√£o √† raiz)\n",
    "7. Reconstru√ß√£o do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ea2e0-2272-46e8-8a5e-1c95190eb9a7",
   "metadata": {},
   "source": [
    "### 3. **Modelo de Classifica√ß√£o**\n",
    "- **Algoritmo**: Random Forest Classifier\n",
    "- **Vantagens**:\n",
    "  - Modelo ensemble (m√∫ltiplas √°rvores)\n",
    "  - Menos propenso a overfitting\n",
    "  - Lida bem com muitas features\n",
    "- **Hiperpar√¢metros otimizados** via GridSearchCV\n",
    "\n",
    "\n",
    "### 4. **Otimiza√ß√£o Autom√°tica**\n",
    "```python\n",
    "GridSearchCV com:\n",
    "- Valida√ß√£o cruzada: 3 folds\n",
    "- M√©trica: Acur√°cia\n",
    "- Teste de m√∫ltiplos par√¢metros\n",
    "- Paraleliza√ß√£o completa\n",
    "```\n",
    "\n",
    "### 2. **Vetoriza√ß√£o TF-IDF**\n",
    "- Considera frequ√™ncia da palavra no documento\n",
    "- Penaliza palavras muito comuns\n",
    "- Captura import√¢ncia relativa das palavras\n",
    "- Configura√ß√µes otimizadas:\n",
    "  - `max_features=5000`\n",
    "  - `ngram_range=(1,2)`\n",
    "  - `min_df=5`\n",
    "  - `max_df=0.7`\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Otimiza√ß√£o Autom√°tica**\n",
    "```python\n",
    "GridSearchCV com:\n",
    "- Valida√ß√£o cruzada: 3 folds\n",
    "- M√©trica: Acur√°cia\n",
    "- Teste de m√∫ltiplos par√¢metros\n",
    "- Paraleliza√ß√£o completa\n",
    "```\n",
    "\n",
    "## üìà Resultados Esperados\n",
    "\n",
    "| M√©trica | Valor Esperado |\n",
    "|---------|---------------|\n",
    "| Acur√°cia | 80-90% |\n",
    "| Precis√£o | > 85% |\n",
    "| Recall | > 85% |\n",
    "| F1-Score | > 85% |\n",
    "\n",
    "## üîß Instala√ß√£o e Execu√ß√£o\n",
    "\n",
    "### 1. Pr√©-requisitos\n",
    "```bash\n",
    "# Vers√£o do Python\n",
    "Python 3.8 ou superior\n",
    "\n",
    "# Instalar depend√™ncias\n",
    "pip install pandas numpy scikit-learn nltk\n",
    "\n",
    "# Baixar recursos do NLTK\n",
    "python -c \"import nltk; nltk.download('punkt_tab'); nltk.download('punkt'); nltk.download('stopwords')\"\n",
    "```\n",
    "\n",
    "### 2. Estrutura do Projeto\n",
    "```\n",
    "analise-sentimentos/\n",
    "‚îú‚îÄ‚îÄ AnaliseDeSentimentos.ipynb    # Notebook principal\n",
    "‚îú‚îÄ‚îÄ imdb-reviews-pt-br.csv       # Dataset\n",
    "‚îú‚îÄ‚îÄ README.md                    # Documenta√ß√£o\n",
    "‚îî‚îÄ‚îÄ requirements.txt            # Depend√™ncias\n",
    "```\n",
    "\n",
    "### 3. Execu√ß√£o\n",
    "```bash\n",
    "# Executar o notebook completo\n",
    "jupyter notebook AnaliseDeSentimentos.ipynb\n",
    "\n",
    "# Ou executar como script Python\n",
    "python AnaliseDeSentimentos.py\n",
    "```\n",
    "\n",
    "## üöÄ Como Usar o Modelo\n",
    "\n",
    "```python\n",
    "from seu_modelo import analisar_sentimento\n",
    "\n",
    "# Exemplos de uso\n",
    "criticas = [\n",
    "    \"Filme incr√≠vel! Atua√ß√µes impec√°veis.\",\n",
    "    \"Perda de tempo total, n√£o recomendo.\",\n",
    "    \"Razo√°vel, poderia ser melhor.\"\n",
    "]\n",
    "\n",
    "for critica in criticas:\n",
    "    resultado = analisar_sentimento(critica)\n",
    "    print(f\"Cr√≠tica: {critica[:50]}...\")\n",
    "    print(f\"Sentimento: {resultado['sentimento']}\")\n",
    "    print(f\"Confian√ßa: {resultado['confianca']:.2%}\")\n",
    "```\n",
    "\n",
    "## üìÅ Estrutura do C√≥digo\n",
    "\n",
    "### M√≥dulos Principais\n",
    "\n",
    "1. **`preprocessamento_avancado()`**\n",
    "   - Fun√ß√£o principal de limpeza de texto\n",
    "   - Suporte a caracteres acentuados em portugu√™s\n",
    "   - Remo√ß√£o inteligente de stopwords\n",
    "\n",
    "2. **`Pipeline` de Machine Learning**\n",
    "   - Integra√ß√£o TF-IDF + Random Forest\n",
    "   - Encapsulamento completo do fluxo\n",
    "   - Facilidade de manuten√ß√£o\n",
    "\n",
    "3. **`GridSearchCV`**\n",
    "   - Busca exaustiva de melhores par√¢metros\n",
    "   - Valida√ß√£o cruzada incorporada\n",
    "   - Paraleliza√ß√£o para performance\n",
    "\n",
    "### Fluxo de Execu√ß√£o\n",
    "```\n",
    "Carregar Dados ‚Üí Pr√©-processar ‚Üí Vetorizar ‚Üí Treinar ‚Üí Otimizar ‚Üí Avaliar ‚Üí Predizer\n",
    "```\n",
    "\n",
    "## üé® Features Implementadas\n",
    "\n",
    "### ‚úÖ Corrigidas do C√≥digo Original\n",
    "- **Pr√©-processamento**: Mant√©m palavras inteiras (n√£o letras soltas)\n",
    "- **Tokeniza√ß√£o**: Usa `punkt_tab` para portugu√™s\n",
    "- **Vetoriza√ß√£o**: TF-IDF em vez de CountVectorizer simples\n",
    "- **Modelo**: Random Forest em vez de Naive Bayes b√°sico\n",
    "\n",
    "### ‚úÖ Otimiza√ß√µes Adicionais\n",
    "- Pipeline organizado com Scikit-learn\n",
    "- Otimiza√ß√£o autom√°tica de hiperpar√¢metros\n",
    "- Valida√ß√£o cruzada para avalia√ß√£o robusta\n",
    "- An√°lise detalhada de erros\n",
    "\n",
    "## üìä An√°lise de Desempenho\n",
    "\n",
    "### M√©tricas de Avalia√ß√£o\n",
    "- **Acur√°cia**: Porcentagem de classifica√ß√µes corretas\n",
    "- **Precis√£o**: Entre as classificadas como positivas, quantas realmente s√£o\n",
    "- **Recall**: Entre todas as positivas reais, quantas foram identificadas\n",
    "- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall\n",
    "\n",
    "### Matriz de Confus√£o\n",
    "```\n",
    "              Predito Negativo  Predito Positivo\n",
    "Real Negativo      TN                FP\n",
    "Real Positivo      FN                TP\n",
    "```\n",
    "\n",
    "## üîÑ Pr√≥ximas Melhorias\n",
    "\n",
    "### 1. Engenharia de Features Avan√ßada\n",
    "- [ ] Contagem de palavras positivas/negativas\n",
    "- [ ] Extra√ß√£o de emoticons e exclama√ß√µes\n",
    "- [ ] An√°lise de senten√ßas por par√°grafo\n",
    "\n",
    "### 2. Modelos Avan√ßados\n",
    "- [ ] XGBoost ou LightGBM\n",
    "- [ ] SVM com kernel n√£o-linear\n",
    "- [ ] Redes Neurais (MLP)\n",
    "\n",
    "### 3. Deep Learning\n",
    "- [ ] LSTM/GRU para contexto sequencial\n",
    "- [ ] BERTimbau (BERT em portugu√™s)\n",
    "- [ ] Fine-tuning de transformers\n",
    "\n",
    "### 4. Sistema em Produ√ß√£o\n",
    "- [ ] API REST com FastAPI\n",
    "- [ ] Sistema de cache de predi√ß√µes\n",
    "- [ ] Monitoramento de performance\n",
    "- [ ] Logs detalhados\n",
    "\n",
    "## üìù Conclus√£o\n",
    "\n",
    "Este projeto demonstra uma implementa√ß√£o completa de an√°lise de sentimentos, abordando desde o pr√©-processamento b√°sico at√© otimiza√ß√µes avan√ßadas. A arquitetura modular permite f√°cil extens√£o e adapta√ß√£o para diferentes dom√≠nios.\n",
    "\n",
    "### Principais Aprendizados\n",
    "1. **Pr√©-processamento √© crucial**: Representa√ß√£o correta dos dados afeta diretamente os resultados\n",
    "2. **TF-IDF > CountVectorizer**: Considera import√¢ncia relativa das palavras\n",
    "3. **Random Forest robusto**: Excelente para problemas de classifica√ß√£o de texto\n",
    "4. **Otimiza√ß√£o sistem√°tica**: GridSearchCV encontra automaticamente os melhores par√¢metros\n",
    "\n",
    "## üë• Contribui√ß√£o\n",
    "\n",
    "Contribui√ß√µes s√£o bem-vindas! Siga estes passos:\n",
    "\n",
    "1. Fork do reposit√≥rio\n",
    "2. Crie uma branch (`git checkout -b feature/nova-feature`)\n",
    "3. Commit suas mudan√ßas (`git commit -m 'Add nova feature'`)\n",
    "4. Push para a branch (`git push origin feature/nova-feature`)\n",
    "5. Abra um Pull Request\n",
    "\n",
    "## üìÑ Licen√ßa\n",
    "\n",
    "Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.\n",
    "\n",
    "## üôè Agradecimentos\n",
    "\n",
    "- Dataset: [IMDB Reviews em Portugu√™s](https://www.kaggle.com/datasets)\n",
    "- Bibliotecas: Scikit-learn, NLTK, Pandas, NumPy\n",
    "- Comunidade de Data Science\n",
    "\n",
    "## üìû Contato\n",
    "\n",
    "Para d√∫vidas ou sugest√µes, entre em contato:\n",
    "\n",
    "**Desenvolvedor**: [Seu Nome]  \n",
    "**Email**: seu.email@exemplo.com  \n",
    "**LinkedIn**: [linkedin.com/in/seu-perfil](https://linkedin.com)\n",
    "\n",
    "---\n",
    "*\"Transformando texto em insights atrav√©s de dados\"* üöÄ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **PRINCIPAIS CORRE√á√ïES APLICADAS:**\n",
    "\n",
    "1. **Corrigido erro do NLTK**: Adicionado download do `punkt_tab`\n",
    "2. **Sequ√™ncia l√≥gica**: Garantida execu√ß√£o na ordem correta\n",
    "3. **Simplifica√ß√£o**: Reduzida complexidade do GridSearchCV para execu√ß√£o mais r√°pida\n",
    "4. **Manuten√ß√£o de contexto**: Todas as vari√°veis s√£o definidas antes do uso\n",
    "\n",
    "## **PR√ìXIMOS PASSOS SUGERIDOS:**\n",
    "\n",
    "1. **Salvar o modelo treinado**:\n",
    "```python\n",
    "import joblib\n",
    "joblib.dump(grid_search, 'modelo_sentimentos.pkl')\n",
    "```\n",
    "\n",
    "2. **Criar API**:\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/analisar\")\n",
    "def analisar(critica: str):\n",
    "    texto_limpo = preprocessamento_avancado(critica)\n",
    "    predicao = grid_search.predict([texto_limpo])[0]\n",
    "    return {\"sentimento\": \"positivo\" if predicao == 1 else \"negativo\"}\n",
    "```\n",
    "\n",
    "3. **Monitoramento**:\n",
    "   - Adicionar logging\n",
    "   - Implementar tracking de performance\n",
    "   - Criar dashboard de m√©tricas\n",
    "\n",
    "O projeto est√° agora funcional e pronto para execu√ß√£o!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893b8ad-a3f8-41d9-a118-16ad80f2905f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
